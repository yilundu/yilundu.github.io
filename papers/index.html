<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" lang="en"><head>
  <title>Improved Contrastive Divergence Training of Energy Based Models</title>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

<meta property="og:image" content="fig/uncond_gen.gif"/>
<meta property="og:title" content="Neural Radiance Flow for 4D View Synthesis and Video Processing" />

<script src="lib.js" type="text/javascript"></script>
<script src="popup.js" type="text/javascript"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-53682931-1', 'auto');
  ga('send', 'pageview');

</script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<script type="text/javascript">
// redefining default features
var _POPUP_FEATURES = 'width=1000,height=1000,resizable=1,scrollbars=1,titlebar=1,status=1';
</script>
<link media="all" href="glab.css" type="text/css" rel="StyleSheet">
<style type="text/css" media="all">
IMG {
    PADDING-RIGHT: 0px;
    PADDING-LEFT: 0px;
    FLOAT: right;
    PADDING-BOTTOM: 0px;
    PADDING-TOP: 0px
}
#primarycontent {
    MARGIN-LEFT: auto; ; WIDTH: expression(document.body.clientWidth >
1000? "1000px": "auto" ); MARGIN-RIGHT: auto; TEXT-ALIGN: left; max-width:
1000px }
BODY {
    TEXT-ALIGN: center
}
</style>

<meta content="MSHTML 6.00.2800.1400" name="GENERATOR"><script src="b5m.js" id="b5mmain" type="text/javascript"></script></head>

<body>

<div id="primarycontent">
<center><h1>Improved Contrastive Divergence Training of Energy Based Models</h1></center>
<center><h2><a href="https://yilundu.github.io/">Yilun Du<sup>1</sup></a>&nbsp;&nbsp;&nbsp;
  <a href="http://www.mit.edu/~lishuang/">Shuang Li<sup>1</sup></a>&nbsp;&nbsp;&nbsp;
  <a href="http://web.mit.edu/cocosci/josh.html">Joshua Tenenbaum<sup>1</sup></a>&nbsp;&nbsp;&nbsp;
  <a href="https://scholar.google.com/citations?user=Vzr1RukAAAAJ&hl=en">Igor Mordatch<sup>2</sup></a></h2></center>
<center><h2>
  <sup>1</sup> MIT CSAIL&nbsp;&nbsp;&nbsp;
  <sup>2</sup> Google Brain
</h2></center>
<center><h2><strong><a href="https://arxiv.org/abs/2012.01316">Paper</a> | <a href="https://github.com/yilundu/improved_contrastive_divergence">Pytorch Code</a></strong> </h2></center>
<br>


<!---
<center><a>
<img src="fig/comp_cartoon.jpg" width="1000"> 
</a></center>
<br>
-->



<p>
<h2>Abstract</h2>

<div style="font-size:14px"><p align="justify">
We propose several different techniques to improve contrastive divergence training of energy-based models (EBMs). We first show that a gradient term neglected in the popular contrastive divergence formulation is both tractable to estimate and is important to avoid training instabilities in previous models. We further highlight how data augmentation, multi-scale processing, and reservoir sampling can be used to improve model robustness and generation quality. Thirdly, we empirically evaluate stability of model architectures and show improved performance on a host of benchmarks and use cases, such as image generation, OOD detection, and compositional generation.
</div>
</p>



<!-- ---------------------------------------------------------------------------------- -->
<a href=""><img style="float: left; padding: 10px; PADDING-RIGHT: 30px;" alt="paper thumbnail" src="fig/paper_thumbnail.jpg" width=170></a>
<br>


<h2>Paper</h2>
<p><a href="paper/ebm.pdf">arxiv</a>,  2020. </p>


<h2>Citation</h2>
<p>Yilun Du, Shuang Li, Joshua Tenenbaum, Igor Mordatch. "Improved Contrastive Divergence Training of Energy Based Models", arxiv.
<a href="fig/citation.txt">Bibtex</a>

</p>


<h2><a href=''>Pytorch Code</a> </h2>

<br><br>

<!-- ---------------------------------------------------------------------------------- -->
<p>
<h2>Method</h2>

<p style="font-size:14px">
Energy based models (EBMs) represent the likelihood of a probability distribution of data by assigning an unnormalized probability scalar (or "energy") to each input data point. This provides significant model flexibility; any arbitrary model that outputs a real number can be used as an energy model. A difficulty however, is that training EBMs is hard, as to properly maximize the likelihood of an energy function, samples must be drawn from the energy model.

In this work we present a set of improvements to contrastive divergence training of EBMs, enabling more stable, high resolution generation with EBMs. In particular we propose to:
</p>

<ul id='cd'>
<li font-size: 6px>
Add a KL loss term into contrastive divergence, which corresponds to a typically ignored gradient. Weshow significantly help stabilize and improve generative performance
</li>

<li font-size: 6px>
Integrate data-augmentation transitions while training EBMs to encourage mode mixing between model samples.
</li>

<li font-size: 6px>
Factorize generation to a set of multi-scale energy functions operating on the input.
</li>

<li font-size: 6px>
Improve sample diversity by maintaing a reservoir buffer of past samples from the model.
</li>
</ul>

<h2>Contrastive Divergence</h2>

<p style="font-size:14px">
A common objective used to train EBMs is <a =href="https://www.cs.toronto.edu/~hinton/absps/tr00-004.pdf">contrastive divergence</a>. Contrastive divergence consists of the following objective:
</p>

<p>
<center><a> <img src="fig/cd.png" style="float:none;width:300px"> </a></center>
</p>

<p style="font-size:14px">
where we the minimize the difference between the KL divergence of the data distribution and EBM distribution, and the KL divergence of finite number of MCMC steps on data distribution and EBM distribution.

This objective has a key gradient (highlighted in red) that is often ignored.
</p>

<p>
<center><a> <img src="fig/cd_grad.png" style="float:none;width:450px"> </a></center>
</p>

<p style="font-size:14px">
We present a loss to capture this gradient (see our paper for details), and find that this missing gradient contributes substantially to the overall training gradient of a EBM.

<!---
<p>
<center><a> <img src="fig/cd_kl.png" style="float:none;width:400px"> </a></center>
</p>
-->



We further show below that that by adding  a KL term into contrastive divergence training of energy models, overall training is greatly stabilized. In the graph below, we investigate the energy difference between real images and generated samples with or without the KL term. Stable EBM training corresponds to an energy difference of around 0. We find that the addition of the KL loss term enables incoperation of architectural blocks such as self-attention and normalization, while the absence of the KL term leads to a necessity of spectral normalization to train models stably.
</p>

<p>
<center><a> <img src="fig/kl_yes.png" style="float:none;width:800px"> </a></center>
</p>

<h2>Data Augmentation</h2>

<p style="font-size:14px">
We illustrate our the overall image generation process with EBMs below. We intersperse Langevin sampling with data augmentation transitions, enabling image sampling chains from our model to traverse across a large number of modes in the energy landscape. 

</p>

<p>
<center><a> <img src="fig/langevin_data.gif" style="float:none;width:480px"> </a></center>
</p>

<p>
<center><a> <img src="fig/uncond_gen.gif" style="float:none;width:320px"> </a></center>
</p>


<p style="font-size:14px">
When comparing samples initialized from the same random noise value, we find that with data augmentation to aid sampling, we get significantly more diverse samples than without. 
</p>

<p>
<center><a> <img src="fig/diverse_sample.gif" style="float:none;width:640px"> </a></center>
</p>


<!---
We propose to decompose our energy function as the compositional sum of energy functions operating on different resolutions of images. We illustrate generations of using either only each individual coarse energy function or an EBM consisting compositional sum of each model.

</p>
<center>
<video width="1080" height="360" controls>
  <source src="fig/multiscale.m4v" type="video/mp4">
  Your browser does not support the video tag.
</video>
</center>
</p>
-->

<h2>Zero Shot Compositional Generation</h2>

<p style="font-size:14px">
EBMs are able to independently compose with other <a href="https://energy-based-model.github.io/compositional-generation-inference/">EBMs</a>, allowing us flexibly compose generation across seperate models. We show that our approach enables compositional generation across different domains.


We independently train EBMs for CelebA factors of age, gender, smiling, and wavy hair. We show below that by adding each energy model in generation, we are able to gradually able to construct and change generations to exhibit each desired factor, as encoded by an individual energy function.
</p>

<!---
<p>
<center><a> <img src="fig/comp_face.gif" style="float:none;width:800px"> </a></center>
</p>
--->

<video width="1080" height="360" controls autoplay>
  <source src="fig/comp_face.m4v" type="video/mp4">
  Your browser does not support the video tag.
</video>



<p style="font-size:14px">
We can further independently train EBMs on rendering attributes of shape, size, position and rotation. By adding independent energy model in generation, we are also able to gradually construct generations that exhibit each desired factor.
</p>

<!---
<p>
<center><a> <img src="fig/comp_blender.gif" style="float:none;width:800px"> </a></center>
</p>
-->

<video width="1080" height="360" controls autoplay>
  <source src="fig/comp_blender.m4v" type="video/mp4">
  Your browser does not support the video tag.
</video>


<h2>Out of Distribution Detection</h2>
<p style="font-size:14px">
We further find that our approach significantly outperforms past energy based models on the task of simply using the likelihood of the EBM for out-of-distribution detection.
</p>


<p>
<center><a> <img src="fig/ood.png" style="float:none;width:450px"> </a></center>
</p>


<h2>Our Additional Work on Energy-Based Models</h2>

<p style="font-size:14px">
If interested, here are additional works from us on utilizing energy models:
</p>

<ul id='relatedwork'>
<li font-size: 15px>
 Yilun Du, Igor Mordatch <a href="https://papers.nips.cc/paper/8619-implicit-generation-and-modeling-with-energy-based-models"><strong>"Implicit Generation and Modeling with Energy Based Models"</strong></a>, in NeurIPS 2019 (Spotlight).
</li>
<li font-size: 15px>
 Yilun Du, Toru Lin, Igor Mordatch <a href="https://arxiv.org/abs/1909.06878"><strong>"Modeling Based Planning with Energy Based Models"</strong></a>, in CORL 2019.
</li>
<li font-size: 15px>
 Yilun Du, Joshua Meier, Jerry Ma, Rob Fergus, Alexander Rives <a href="https://openreview.net/pdf?id=S1e_9xrFvS"><strong>"Energy-Based Models For Atomic-Resolution
Protein Conformations"</strong></a>, in ICLR 2020 (Spotlight).
</li>
<li font-size: 15px>
 Yilun Du, Shuang Li, Igor Mordatch <a href="https://arxiv.org/pdf/2004.06030.pdf"><strong>"Compositional Visual Generation with Energy Based Models"</strong></a>, in NeurIPS 2020 (Spotlight).
</li>
<li font-size: 15px>
 Shuang Li, Yilun Du,  Gido M. Van de Ven, Antonio Torralba, Igor Mordatch <a href="https://energy-based-model.github.io/Energy-Based-Models-for-Continual-Learning/"><strong>"Energy-Based Models for Continaul Learning"</strong></a>, arxiv.
</li>
</ul>



<!---
<br>
<h2>Acknowledgement</h2>
<p align="justify"></p>
-->

<div style="display:none">
<script type="text/javascript" src="http://gostats.com/js/counter.js"></script>
<script type="text/javascript">_gos='c3.gostats.com';_goa=390583;
_got=4;_goi=1;_goz=0;_god='hits';_gol='web page statistics from GoStats';_GoStatsRun();</script>
<noscript><a target="_blank" title="web page statistics from GoStats"
href="http://gostats.com"><img alt="web page statistics from GoStats"
src="http://c3.gostats.com/bin/count/a_390583/t_4/i_1/z_0/show_hits/counter.png"
style="border-width:0" /></a></noscript>
</div>
</body></html
>

